export const metadata = {
  date: "2022-02-18T19:26:54.937Z",
  title: "Let the Browser Do It for You",
  description: "A dummy description",
  image: require("./browser.png"),
  imageAlt: "A little browser lifting weights",
};

Browsers are an incredible feat of engineering. According to wikipedia, the Chromium codebase contains about [35 million lines of source code](<https://en.wikipedia.org/wiki/Chromium_(web_browser)#:~:text=35%20million%20source%20lines%20of%20code.>).
It's really impressive to me that they work at all.

Using built-in browser features is not a novel idea. Choosing `border-radius` over background sprites may seem obvious nowadays but it was not always the case. There are many things we take for granted that were just hopes and dreams not so long ago.

I've realised that once I have found a way of doing something, I tend to stick with it and accept it as the status quo. I often find myself reusing techniques from my old bag of tricks without checking to see if anything changed in the browser landscape.

This post is mostly a reminder to myself that I don't always need to re-invent the wheel and that I can, in most cases, rely on the browser to do the heavy lifting for me.

---

_I need to mention that it's not always possible to use some of the tricks highlighted in this article if you are building an [isomorphic application](https://en.wikipedia.org/wiki/Isomorphic_JavaScript). Some techniques rely on browser features that are not available in the Node.js runtime. But hey, things move fast, I'm looking at you [#41749](https://github.com/nodejs/node/pull/41749)._

---

## URLs

Let's start with the basics. Dealing with URLs is pretty common when developing web applications. It's also quite hard to get right, better let the browser do the magic.

### Parsing URLs

I think we've all been there before. We need to extract some data from a URL, so we whip out the `slice` method and start slicing pieces off.

```javascript
// ðŸš« Don't do this (keep reading)

const getQueryStringFromUrl = (url) => {
  return url.slice(url.indexOf("?"));
};

// Works
console.log(getQueryStringFromUrl("https://example.com/?test=1"));

// Fails
console.log(getQueryStringFromUrl("https://example.com/?test=1#hash"));
console.log(getQueryStringFromUrl("https://example.com/"));
```

We start testing our code and then realize there are flaws in our implementation. At this point we can decide to go back to the drawing board but even then, who knows what else we forgot.

**Parsing URLs is hard**, and doing it by hand is rarely a good idea.

Luckily for us, browsers ship with the [`URL`](https://developer.mozilla.org/en-US/docs/Web/API/URL) API which means we can reliably parse URLs with a single line of code:

```javascript
console.log(new URL("https://example.com/?test=1").search);
console.log(new URL("https://example.com/?test=1#hash").search);
console.log(new URL("https://example.com/").search);
```

It can also be used to extract any other part of a URL:

```javascript
const url = new URL("https://example.com:3000/path?test=1#hash");

console.log(url.protocol);
console.log(url.hostname);
console.log(url.pathname);
console.log(url.search);
console.log(url.hash);
// And many others...
```

Here's a list of all the properties that are supported: https://developer.mozilla.org/en-US/docs/Web/API/URL#properties

### Absolute URLs

Another great thing about `URL` is that it can convert relative URLs into absolute URLs, similar to [`url.resolve`](https://nodejs.org/api/url.html#urlresolvefrom-to) in Node.js.

```javascript
const toAbsoluteUrl = (base, relativeUrl) => {
  return new URL(relativeUrl, base).toString();
};

const BASE_URL = "https://base-url/path/";

console.log(toAbsoluteUrl(BASE_URL, "/absolute-path"));
console.log(toAbsoluteUrl(BASE_URL, "relative-path"));
console.log(toAbsoluteUrl(BASE_URL, "../relative-path"));
```

### Query String Parsing

Browsers also have the ability to parse query strings in a similar fashion to the `URL` constructor. The API is called [`URLSearchParams`](https://developer.mozilla.org/en-US/docs/Web/API/URLSearchParams) and it's packed with everything we could possibly need when it comes to query parameters.

This example shows how we can extract parameters from a query string:

```javascript
const params = new URLSearchParams("?query=1&test=Hello%20world");

console.log(params.get("query"));
console.log(params.get("test"));
```

Here's a list of all the methods that are supported: https://developer.mozilla.org/en-US/docs/Web/API/URLSearchParams#methods

We can also use a combination of `URLSearchParams` and [`Object.fromEntries`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/fromEntries) to turn query strings into plain JavaScript objects:

```javascript
const parseQueryString = (queryString) => {
  return Object.fromEntries(new URLSearchParams(queryString));
};

console.log(parseQueryString("?query=1&test=Hello%20World"));
```

### Query params stringification

Great, we can parse query strings but what about the opposite. What if we have a bunch of values and we want to turn them into a query string?

I've lost count of the number of times I've seen API calls like the one below (**disclaimer:** I'm guilty of having done this several times).

```javascript
// ðŸš« Don't do this (keep reading)

const fetchProducts = ({ brand, inStock, limit }) => {
  return fetch(
    `https://api.example.com/products?brand=${encodeURIComponent(
      brand
    )}&inStock=${inStock}&limit=${limit}`
  );
};

await fetchProducts({
  brand: "Bang & Olufsen",
  inStock: true,
  limit: 10,
});
```

While this works, there are many things that can be improved.

- It is hard to read - even more so with prettier doing its best to keep the line length under control.
- It's fragile - we're one bad keystroke away from messing up our URL.
- We have to manually encode string parameters with `encodeURIComponent`.

I've used the [qs](https://www.npmjs.com/package/qs) package in the past to address these issues but there is no need to add yet another package to our dependencies, we can once again rely on [`URLSearchParams`](https://developer.mozilla.org/en-US/docs/Web/API/URLSearchParams) to do the job for us.

I think we can all agree that this is much more readable:

```javascript
const fetchProducts = (params) => {
  return fetch(
    `https://api.example.com/products?${new URLSearchParams(params)}`
  );
};

await fetchProducts({
  brand: "Bang & Olufsen",
  inStock: true,
  limit: 10,
});
```

### Utility function

We might want to create an abstraction around `URLSearchParams` if we prefer a more succinct API.

```javascript
// **************************************
// Utility functions
// **************************************

const parse = (queryString) => {
  return Object.fromEntries(new URLSearchParams(queryString));
};

const stringify = (queryObject) => {
  return new URLSearchParams(queryObject).toString();
};

const qs = {
  parse,
  stringify,
};

export default qs;

// **************************************
// Usage
// **************************************

import qs from "./qs.util";

console.log(qs.parse("?query=1&test=Hello%20World"));

console.log(
  qs.stringify({
    query: "1",
    test: "Hello World",
  })
);
```

## Strings

Doing a check with `String.indexOf(...) > -1` should be a thing of the past. Browsers have made our lives a lot easier with the addition of methods such as `includes` and `startsWith`.

```javascript
const startsWith = "Hello world".startsWith("Hello");
const endsWith = "Hello world".endsWith("world");
const includes = "Hello world".includes("world");

console.log(startsWith, endsWith, includes);
```

Here's the full list of supported methods: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String#instance_methods

### Removing Accents

Removing diacritics from a string is definitely not something I want to do by hand. I've previously relied on lodash's
[`deburr`](https://lodash.com/docs/4.17.15#deburr) function to do the job but I recently found out that it can be done with this one-liner:

```javascript
const removeAccents = (str) => {
  return str.normalize("NFD").replace(/[\u0300-\u036f]/g, "");
};

const output = removeAccents("HÃ©tÃ©rogÃ©nÃ©itÃ©");

console.log(output);
```

### HTML Encoding

We sometimes need to sanitize untrusted strings to prevent XSS vulnerabilities. We usually do this by encoding HTML entities so that they are not interpreted as code when rendered in our document.

If we look on the internet for how to HTML-encode a piece of text, we mostly find answers that involve regular expressions:

- [How to encode a string in JavaScript for displaying in HTML?](https://stackoverflow.com/questions/14129953/how-to-encode-a-string-in-javascript-for-displaying-in-html)
- [How to escape HTML](https://stackoverflow.com/questions/3043775/how-to-escape-html)

Personally, the farther I stay away from regular expressions the better, especially when writing code that revolves around security. If there's one thing browsers are good at, it's HTML.

In this example we leverage the browser's built-in HTML parser to safely encode a piece of untrusted data.

```javascript
const encodeHtmlEntities = (str) => {
  const parent = document.createElement("div");

  parent.appendChild(new Text(str));

  return parent.innerHTML;
};

const safeString = encodeHtmlEntities(
  `Hello world <img src="" onerror="alert('xss')" />`
);

console.log(safeString);
```

The special ingredient here is the [`Text`](https://developer.mozilla.org/en-US/docs/Web/API/Text) constructor. The browser will properly escape any string you throw at it. You can learn more about it here: https://developer.mozilla.org/en-US/docs/Web/API/Text

### Extract text from HTML

Data can be messy sometimes. We might be pulling data from an old API built by someone who thought it was a good idea to store HTML in their database.

The [`DOMParser`](https://developer.mozilla.org/en-US/docs/Web/API/DOMParser/parseFromString) API can help us in such scenario. It provides a way to leverage the browser's built-in DOM parser without interfering with the main document.

```javascript
const stripHtml = (html) => {
  const { documentElement } = new DOMParser().parseFromString(
    html,
    "text/html"
  );

  return documentElement.textContent;
};

console.log(stripHtml(`<p>This is some text</p>`));
console.log(stripHtml(`<img src="" onerror="alert('xss')" />`));
```

I sincerely hope you never have to but you can also use the `DOMParser` API to parse XML documents: https://developer.mozilla.org/en-US/docs/Web/API/DOMParser/parseFromString

## Client-side Validations

Client-side validation can be a pain. There is a lot of disagreement about how user inputs should be validated. Most of the debate is over which regular expression is best for performing a given task. I prefer to look from the sidelines and let the browser do the validation for me when possible.

### Validating Email Addresses

As far as I know, there is no built-in function we can call to get a clear [yes or no](https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/canPlayType) whether a given address is valid but we can use the [Constraint Validation API](https://developer.mozilla.org/en-US/docs/Web/API/Constraint_validation) and a bit of creativity to achieve just that:

```javascript
const validateEmail = (email) => {
  const input = document.createElement("input");

  input.type = "email";
  input.required = true;
  input.value = email;

  return input.checkValidity();
};

console.log(validateEmail("test@example.com"));
console.log(validateEmail("test@localhost"));
console.log(validateEmail("not-an-email"));
```

**Note:** this code won't work server-side as it relies on the DOM but this doesn't mean that we shouldn't validate email addresses on the backend too.

### URL Validation

The [`URL`](https://developer.mozilla.org/en-US/docs/Web/API/URL) constructor turn out to be useful once again. Here we rely on the fact that it throws an exception if the given URL is invalid in addition to making sure the protocol matches a set of expected values:

```javascript
const validateUrl = (url) => {
  try {
    return ["http:", "https:"].includes(new URL(url).protocol);
  } catch {
    return false;
  }
};

console.log(validateUrl(`https://example.com/path/`));
console.log(validateUrl(`wss://example.com/path/`));
console.log(validateUrl(`javascript:alert("XSS")`));
console.log(validateUrl(`not-a-url`));
```

## Wrapping up

As you can see, there's a bit of a trade-off. It's not as simple as importing a package and calling it a day. We still have to write a slight amount of code to leverage these browser features but the advantage is that we are now relying on code that has been battle-tested extensively and more importantly, we haven't increased the size of our JavaScript bundle.

This list is non-exhaustive but I think we get the idea.

As always, make sure these features are supported by the browsers you are targeting.

**Stay safe.**
